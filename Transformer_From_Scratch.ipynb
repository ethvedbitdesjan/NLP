{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer_From_Scratch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO8j2s18hf+5nCI2u0FeAOQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ethvedbitdesjan/NLP/blob/main/Transformer_From_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-B-b4JivZ06"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F \n",
        "import torch.nn as nn\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(query, key, value):\n",
        "    temp = query.bmm(key.transpose(1, 2))\n",
        "    softmax_scale = F.softmax((temp/(query.size(-1) ** 0.5)), dim=-1)\n",
        "    return softmax_scale.bmm(value)"
      ],
      "metadata": {
        "id": "PW3QIM7j0ByL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionHead(nn.Module):\n",
        "    def __init__(self, in_dim, q_dim, k_dim):\n",
        "        super().__init__()\n",
        "        self.q = nn.Linear(in_dim, q_dim)\n",
        "        self.k = nn.Linear(in_dim, k_dim)\n",
        "        self.v = nn.Linear(in_dim, k_dim)\n",
        "\n",
        "    def forward(self, query, key, value):\n",
        "        return scaled_dot_product_attention(self.q(query), self.k(key), self.v(value))"
      ],
      "metadata": {
        "id": "YrD-o9T33KC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, in_dim, q_dim, k_dim):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList(\n",
        "            [AttentionHead(in_dim, q_dim, k_dim) for _ in range(num_heads)]\n",
        "        )\n",
        "        self.linear = nn.Linear(num_heads * k_dim, in_dim)\n",
        "\n",
        "    def forward(self, query, key, value):\n",
        "        return self.linear(\n",
        "            torch.cat([h(query, key, value) for h in self.heads], dim=-1)\n",
        "        )"
      ],
      "metadata": {
        "id": "_ZhyoTDV3U8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feed_forward(in_dimput = 512, feedforward_dim = 2048):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(in_dimput, feedforward_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(feedforward_dim, in_dimput),\n",
        "    )"
      ],
      "metadata": {
        "id": "Pp1nAD-1FH2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_dim = 512,\n",
        "        num_heads = 6,\n",
        "        feedforward_dim = 2048,\n",
        "        dropout = 0.2,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        q_dim = k_dim = max(model_dim // num_heads, 1)\n",
        "        self.layer1 = MultiHeadAttention(num_heads, model_dim, q_dim, k_dim)\n",
        "\n",
        "        self.norm = nn.LayerNorm(model_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.layer2 = feed_forward(model_dim, feedforward_dim)\n",
        "\n",
        "    def forward(self, src):\n",
        "\n",
        "        multi_attend_out = self.dropout(self.layer1(src, src, src))\n",
        "        print(multi_attend_out.size(), \"multi_attend_out\")\n",
        "        attend_out_normed = self.norm(src+multi_attend_out)\n",
        "        print(attend_out_normed.size(), \"att_out_norm\")\n",
        "        perceptron_out = self.dropout(self.layer2(attend_out_normed))\n",
        "        print(perceptron_out.size(), \"percep_ou\")\n",
        "        return self.norm(attend_out_normed+perceptron_out)"
      ],
      "metadata": {
        "id": "gXg4Ox5fG97i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def position_encoding(seq_len, model_dim, device = torch.device(\"cpu\")):\n",
        "    pos = torch.arange(seq_len, dtype=torch.float, device=device).reshape(1, -1, 1)\n",
        "    dim = torch.arange(model_dim, dtype=torch.float, device=device).reshape(1, 1, -1)\n",
        "    phase = pos / (1e4 ** (dim // model_dim))\n",
        "\n",
        "    return torch.where(dim.long() % 2 == 0, torch.sin(phase), torch.cos(phase))"
      ],
      "metadata": {
        "id": "o-PRjNdk_R9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoderLayer(nn.Module):\n",
        "    def __init__(self, model_dim= 512, num_heads= 6, feedforward_dim= 2048, dropout= 0.2):\n",
        "        super().__init__()\n",
        "        q_dim = k_dim = max(model_dim // num_heads, 1)\n",
        "        self.attention1 = MultiHeadAttention(num_heads, model_dim, q_dim, k_dim)\n",
        "\n",
        "        self.attention2 = MultiHeadAttention(num_heads, model_dim, q_dim, k_dim)\n",
        "\n",
        "        self.feed_forward = feed_forward(model_dim, feedforward_dim)\n",
        "        self.norm = nn.LayerNorm(model_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, tgt, memory):\n",
        "        attend_out_1 = self.dropout(self.attention1(tgt, tgt, tgt))\n",
        "        attend_out_1_normed = self.norm(tgt+attend_out_1)\n",
        "\n",
        "        attend_out_2= self.dropout(self.attention2(attend_out_1_normed, memory, memory))\n",
        "        attend_out_2_normed = self.norm(attend_out_1_normed+attend_out_2)\n",
        "\n",
        "        perceptron_out = self.dropout(self.feed_forward(attend_out_2_normed))\n",
        "\n",
        "        return self.norm(attend_out_2_normed+perceptron_out)"
      ],
      "metadata": {
        "id": "2IGGXa9XO_SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_layers= 6,\n",
        "        model_dim= 512,\n",
        "        num_heads= 8,\n",
        "        feedforward_dim= 2048,\n",
        "        dropout = 0.2\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        \n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                TransformerEncoderLayer(model_dim, num_heads, feedforward_dim, dropout)\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def forward(self, src):\n",
        "        seq_len, dimension = src.size(1), src.size(2)\n",
        "        print(src.size())\n",
        "        src += position_encoding(seq_len, dimension)\n",
        "        print(src.size(), \"pos\", position_encoding(seq_len, dimension).size())\n",
        "        for layer in self.layers:\n",
        "            src = layer(src)\n",
        "            print(src.size(), \"encoder...\")\n",
        "        return src"
      ],
      "metadata": {
        "id": "yabRY7eQOIUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_layers= 6,\n",
        "        model_dim= 512,\n",
        "        num_heads= 8,\n",
        "        feedforward_dim = 2048,\n",
        "        dropout= 0.2,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                TransformerDecoderLayer(model_dim, num_heads, feedforward_dim, dropout)\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "        self.linear = nn.Linear(model_dim, model_dim)\n",
        "\n",
        "    def forward(self, tgt, memory):\n",
        "        seq_len, dimension = tgt.size(1), tgt.size(2)\n",
        "        print(tgt.size())\n",
        "        tgt += position_encoding(seq_len, dimension)\n",
        "        print(tgt.size())\n",
        "        for layer in self.layers:\n",
        "            tgt = layer(tgt, memory)\n",
        "            print(tgt.size(), \"decoder...\")\n",
        "        return torch.softmax(self.linear(tgt), dim=-1)"
      ],
      "metadata": {
        "id": "gJCHMWq0UZ5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, num_encoder_layers = 6, num_decoder_layers = 6, model_dim = 512, num_heads = 6, feedforward_dim = 2048, dropout = 0.2, activation = nn.ReLU()):\n",
        "        super().__init__()\n",
        "        self.encoder = TransformerEncoder(\n",
        "            num_layers=num_encoder_layers,\n",
        "            model_dim=model_dim,\n",
        "            num_heads=num_heads,\n",
        "            feedforward_dim=feedforward_dim,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "        self.decoder = TransformerDecoder(\n",
        "            num_layers=num_decoder_layers,\n",
        "            model_dim=model_dim,\n",
        "            num_heads=num_heads,\n",
        "            feedforward_dim=feedforward_dim,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        return self.decoder(tgt, self.encoder(src))"
      ],
      "metadata": {
        "id": "CvNJbrzkRYxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src = torch.rand(16, 32, 512)\n",
        "tgt = torch.rand(16, 16, 512)\n",
        "model = Transformer()\n",
        "out = model(src, tgt)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0v7soOqSdPV",
        "outputId": "595d5f89-c7f0-4a3a-fea2-ae3754e801fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 32, 512])\n",
            "torch.Size([16, 32, 512]) pos torch.Size([1, 32, 512])\n",
            "torch.Size([16, 32, 512]) multi_attend_out\n",
            "torch.Size([16, 32, 512]) att_out_norm\n",
            "torch.Size([16, 32, 512]) percep_ou\n",
            "torch.Size([16, 32, 512]) encoder...\n",
            "torch.Size([16, 32, 512]) multi_attend_out\n",
            "torch.Size([16, 32, 512]) att_out_norm\n",
            "torch.Size([16, 32, 512]) percep_ou\n",
            "torch.Size([16, 32, 512]) encoder...\n",
            "torch.Size([16, 32, 512]) multi_attend_out\n",
            "torch.Size([16, 32, 512]) att_out_norm\n",
            "torch.Size([16, 32, 512]) percep_ou\n",
            "torch.Size([16, 32, 512]) encoder...\n",
            "torch.Size([16, 32, 512]) "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multi_attend_out\n",
            "torch.Size([16, 32, 512]) att_out_norm\n",
            "torch.Size([16, 32, 512]) percep_ou\n",
            "torch.Size([16, 32, 512]) encoder...\n",
            "torch.Size([16, 32, 512]) multi_attend_out\n",
            "torch.Size([16, 32, 512]) att_out_norm\n",
            "torch.Size([16, 32, 512]) percep_ou\n",
            "torch.Size([16, 32, 512]) encoder...\n",
            "torch.Size([16, 32, 512]) multi_attend_out\n",
            "torch.Size([16, 32, 512]) att_out_norm\n",
            "torch.Size([16, 32, 512]) percep_ou\n",
            "torch.Size([16, 32, 512]) encoder...\n",
            "torch.Size([16, 16, 512])\n",
            "torch.Size([16, 16, 512])\n",
            "torch.Size([16, 16, 512]) decoder...\n",
            "torch.Size([16, 16, 512]) decoder...\n",
            "torch.Size([16, 16, 512]) decoder...\n",
            "torch.Size([16, 16, 512]) decoder...\n",
            "torch.Size([16, 16, 512]) decoder...\n",
            "torch.Size([16, 16, 512]) decoder...\n",
            "torch.Size([16, 16, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.rand(1, 3, 5)\n",
        "t2 = torch.rand(3, 3, 5)\n",
        "\n",
        "print(t2, t1)\n",
        "t2 +=t1\n",
        "print(t2, t2.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIpumvF4Seql",
        "outputId": "49486cad-76af-4df9-b6c0-56b37f687b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.5805, 0.7351, 0.9314, 0.6451, 0.9990],\n",
            "         [0.6803, 0.9837, 0.7175, 0.3201, 0.7552],\n",
            "         [0.1876, 0.6099, 0.9486, 0.7384, 0.4878]],\n",
            "\n",
            "        [[0.1423, 0.9400, 0.3453, 0.8712, 0.3623],\n",
            "         [0.1356, 0.1505, 0.4291, 0.3869, 0.0773],\n",
            "         [0.7850, 0.4236, 0.9965, 0.5007, 0.3655]],\n",
            "\n",
            "        [[0.6787, 0.8164, 0.2383, 0.6309, 0.7243],\n",
            "         [0.1019, 0.3964, 0.9076, 0.3677, 0.6168],\n",
            "         [0.6515, 0.6581, 0.3663, 0.9815, 0.1386]]]) tensor([[[0.2268, 0.5846, 0.2379, 0.6112, 0.0735],\n",
            "         [0.6263, 0.5724, 0.7261, 0.7328, 0.1121],\n",
            "         [0.7249, 0.4095, 0.3130, 0.4591, 0.0007]]])\n",
            "tensor([[[0.8073, 1.3197, 1.1693, 1.2563, 1.0725],\n",
            "         [1.3066, 1.5561, 1.4436, 1.0529, 0.8673],\n",
            "         [0.9125, 1.0194, 1.2616, 1.1974, 0.4885]],\n",
            "\n",
            "        [[0.3691, 1.5246, 0.5832, 1.4825, 0.4358],\n",
            "         [0.7619, 0.7229, 1.1552, 1.1197, 0.1894],\n",
            "         [1.5099, 0.8331, 1.3095, 0.9597, 0.3662]],\n",
            "\n",
            "        [[0.9055, 1.4010, 0.4762, 1.2422, 0.7978],\n",
            "         [0.7283, 0.9688, 1.6338, 1.1005, 0.7289],\n",
            "         [1.3764, 1.0676, 0.6793, 1.4405, 0.1393]]]) torch.Size([3, 3, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wSrPDbqyQ_eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xS2gFeYTUDMy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}